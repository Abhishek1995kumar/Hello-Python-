                                                         YouTube Data Scrap Through Beautifulsoup

from bs4 import BeautifulSoup
import time
import csv
import re
import requests
import matplotlib

channel_name = 'AajTak'

def get_soup_data(url):

    url = 'https://www.youtube.com/watch?v=IupK-KpnSe4&ab_channel=AajTak'
    response = requests.get(url)
    if response.status_code != 200:
        return None
    time.sleep(10)     
    soup = BeautifulSoup(response.text, 'html.parser')
    return soup.text

def aajtak_links():
    soup1 = get_soup_data(f'https://www.youtube.com/user/{channel_name}/playlists')
    if 'This channel does not exist' in soup1.text:
        raise ValueError('This channel does not exist :' + channel_name)

    play_list_atag = soup1.find_all('a',{'href': re.compile(f'{channel_name}/playlists)')})
    element = [{'title': x.text.strip(), 'link' : fix_url(x['href'])} for x in play_list_atag if x.span
               and ('shelf_id=0' not in x['href'])]

    if len(element) ==0:
        element = [{
            'title' : 'section',
            'link' : f'https://www.youtube.com/{channel_name}/playlists'
        }]
        return element

def fix_url(url):
    if url[0] == '/':
        return 'https://www.youtube.com' + url
    else:
        return url

def get_playlist(section):
    print(f'Getting Playlists for Section : {section["title"]}')
    soup1 = get_soup_data(section['link'])
    if soup1 == None:
        return [{'title':'No Playlists','link' : f'https://www.youtube.com/{channel_name}/video'}]
    divs = soup1('a',class_='yt-uix-tile-link')

    playlists = []
    for d in divs:
        title = d.text
        if title != 'Liked video':
            link = fix_url(d['href'])
            playlists.append({'title': title, 'link': link})
    if playlists == []:
        return  [{
            'title' : 'No Playlists',
            'link' : f'https://www.youtube.com/{channel_name}/video'
        }]
    return playlists

def add_video(playlist):
    soup1 = get_soup_data(playlist['link'])
    print(f'Playlist for title : {playlist["title"]}')
    item = soup1('a',class_='yt-uix-tile-link')

    video = []
    for y in item:
        d = {}
        d['title'] = y.text.strip()
        link = fix_url(y['href'])
        d['link'] = link
        t = y.find.next('span',{'aria-label': True})
        d['time'] = t.text if t else 'NA'
        print(f'Open Video "{d["title"]}" for details', end=" ")
        vsoup = get_soup_data(link)
        print('* read,now processor', end="")

        views = vsoup.find('div',class_='watch-view-count').extract
        d['views'] = ''.join(c for c in views if c in '01234')
        d['publication_date'] = vsoup.find(
            'strong',
            class_= 'watch-time-text'
        ).extract[len('Published On ')-1:]

        d['discription'] = vsoup.find('div',id='watch-discription-text').extract

        id = vsoup.find('meta',itemprop='videoid')['content']
        d['short_link'] = f'https://www.youtube/{id}'
        like = vsoup.find('button',class_='like-button-renderer-like-button')
        d['likes'] = like.find('span',class_='yt-uix-button-content').extract

        dislike = vsoup.find('button',class_='like-button-renderer-like-button')
        d['dislikes'] = dislike.find('span', class_='yt-uix-button-content').extract
        video.append(d)
        print('* finished aajtak video')

        playlist['videos'] = video

def tag(t,c):
    return f'<{t}>{c}</{t}>'

def link(text,url):
    return f'<a href="{url}">{text}</a>'

